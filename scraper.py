import pandas as pd
import pymongo
from pymongo import MongoClient
import uuid
from datetime import datetime
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def connect_mongodb():
    """Connexion √† MongoDB"""
    try:
        client = MongoClient("mongodb://localhost:27017/")
        db = client["harcelement"]
        collection = db["posts"]
        logger.info("Connexion MongoDB √©tablie")
        return client, db, collection
    except Exception as e:
        logger.error(f"Erreur MongoDB: {e}")
        return None, None, None

def load_dataset(file_path):
    """Charge le dataset CSV"""
    try:
        df = pd.read_csv(file_path)
        logger.info(f"Dataset charg√©: {len(df)} lignes")
        print(f"Colonnes disponibles: {list(df.columns)}")
        print(df.head())
        return df
    except Exception as e:
        logger.error(f"Erreur chargement CSV: {e}")
        return None

def clean_data(df):
    """Nettoie et pr√©pare les donn√©es"""
    # Trouve les colonnes automatiquement
    text_col = None
    label_col = None
    type_col = None
    
    # Cherche les colonnes par nom
    for col in df.columns:
        col_lower = col.lower()
        if 'text' in col_lower or 'message' in col_lower or 'tweet' in col_lower:
            text_col = col
        elif 'label' in col_lower or 'class' in col_lower:
            label_col = col
        elif 'type' in col_lower or 'category' in col_lower:
            type_col = col
    
    # Valeurs par d√©faut si pas trouv√©es
    if not text_col:
        text_col = df.columns[0]  # Premi√®re colonne
    if not label_col:
        label_col = df.columns[-1]  # Derni√®re colonne
    if not type_col:
        type_col = label_col
    
    print(f"Colonnes utilis√©es - Texte: {text_col}, Label: {label_col}, Type: {type_col}")
    
    # Supprime les lignes vides
    df_clean = df.dropna(subset=[text_col])
    df_clean = df_clean[df_clean[text_col].str.strip() != '']
    
    logger.info(f"Donn√©es nettoy√©es: {len(df_clean)} lignes")
    return df_clean, text_col, label_col, type_col

def create_documents(df, text_col, label_col, type_col):
    """Cr√©e les documents pour MongoDB"""
    documents = []
    
    for _, row in df.iterrows():
        doc = {
            "id_post": str(uuid.uuid4()),
            "text": str(row[text_col]).strip(),
            "label": str(row[label_col]),
            "type": str(row[type_col]) if type_col in row else str(row[label_col]),
            "created_at": datetime.utcnow(),
            "processed": False,
            "source": "kaggle_dataset"
        }
        documents.append(doc)
    
    logger.info(f"Documents cr√©√©s: {len(documents)}")
    return documents

def insert_data(collection, documents):
    """Ins√®re les donn√©es dans MongoDB"""
    try:
        # Supprime l'ancienne collection si elle existe
        collection.drop()
        
        # Ins√®re les nouveaux documents
        result = collection.insert_many(documents)
        
        # Cr√©e des index
        collection.create_index("id_post", unique=True)
        collection.create_index("label")
        collection.create_index("type")
        
        logger.info(f"Documents ins√©r√©s: {len(result.inserted_ids)}")
        return True
    except Exception as e:
        logger.error(f"Erreur insertion: {e}")
        return False

def verify_data(collection):
    """V√©rifie les donn√©es ins√©r√©es"""
    try:
        total = collection.count_documents({})
        print(f"\nTotal documents: {total}")
        
        # Statistiques par label
        pipeline = [{"$group": {"_id": "$label", "count": {"$sum": 1}}}]
        stats = list(collection.aggregate(pipeline))
        print("\nR√©partition par label:")
        for stat in stats:
            print(f"  {stat['_id']}: {stat['count']}")
        
        # √âchantillon
        print("\n√âchantillon de donn√©es:")
        for doc in collection.find().limit(2):
            print(f"  Label: {doc['label']} | Type: {doc['type']}")
            print(f"  Texte: {doc['text'][:80]}...")
            print()
            
    except Exception as e:
        logger.error(f"Erreur v√©rification: {e}")

def main():
    """Fonction principale"""
    print("=== CHARGEMENT DU DATASET DE CYBERHARC√àLEMENT ===\n")
    
    # Param√®tre √† modifier selon votre fichier
    csv_file = "bullying.csv"  # Changez le nom ici
    
    # 1. Connexion MongoDB
    client, db, collection = connect_mongodb()
    if collection is None:
        print("‚ùå Impossible de se connecter √† MongoDB")
        return
    
    try:
        # 2. Chargement du CSV
        print("üìÅ Chargement du dataset...")
        df = load_dataset(csv_file)
        if df is None:
            print("‚ùå Impossible de charger le dataset")
            return
        
        # 3. Nettoyage des donn√©es
        print("\nüßπ Nettoyage des donn√©es...")
        df_clean, text_col, label_col, type_col = clean_data(df)
        
        # 4. Cr√©ation des documents
        print("\nüìù Cr√©ation des documents...")
        documents = create_documents(df_clean, text_col, label_col, type_col)
        
        # 5. Insertion dans MongoDB
        print("\nüíæ Insertion dans MongoDB...")
        if insert_data(collection, documents):
            print("‚úÖ Donn√©es ins√©r√©es avec succ√®s")
        else:
            print("‚ùå Erreur lors de l'insertion")
            return
        
        # 6. V√©rification
        print("\nüîç V√©rification des donn√©es:")
        verify_data(collection)
        
        print("\n‚úÖ PROCESSUS TERMIN√â AVEC SUCC√àS!")
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")
    
    finally:
        if client:
            client.close()

if __name__ == "__main__":
    main()